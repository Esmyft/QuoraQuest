{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used for outputting the design matrix as <code>X.csv</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import marisa_count_vectorizer\n",
    "import marisa_vectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tag import pos_tag\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, CountVectorizer\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.metrics.pairwise import paired_cosine_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "import scorer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_train.replace(np.nan, \"\", regex=True, inplace=True)\n",
    "y = df_train[\"is_duplicate\"].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    X_df = pd.read_csv(\"X_df.csv\")\n",
    "except:\n",
    "    X_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cosine-similarity of word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_qns = pd.read_csv(\"all_qns.csv\", encoding=\"latin1\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = []\n",
    "    for token in tokens:\n",
    "        stems.append(SnowballStemmer().stem(token))\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = HashingVectorizer(tokenizer=tokenize, stop_words=set(stopwords.words(\"english\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5b922f7a27e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_qns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vectorizer.fit(np.asarray(all_qns.values.astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wmi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-e89a1123a8a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SELECT WorkingSet FROM Win32_PerfRawData_PerfProc_Process WHERE IDProcess=%d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWorkingSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmemory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-e89a1123a8a5>\u001b[0m in \u001b[0;36mmemory\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[1;32mfrom\u001b[0m \u001b[0mwmi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWMI\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWMI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SELECT WorkingSet FROM Win32_PerfRawData_PerfProc_Process WHERE IDProcess=%d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wmi'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cosine-similarity of TF-IDF transform (X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_qns = pd.read_csv(\"all_qns.csv\", encoding=\"latin1\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MarisaTfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "           dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "           lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "           ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
       "           smooth_idf=True,\n",
       "           stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', '...aven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn'],\n",
       "           strip_accents=None, sublinear_tf=False,\n",
       "           token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "           vocabulary=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = marisa_vectorizer.MarisaTfidfVectorizer(ngram_range=(1, 2), stop_words=stopwords.words(\"english\"))\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MarisaTfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "           dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "           lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "           ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
       "           smooth_idf=True,\n",
       "           stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', '...aven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn'],\n",
       "           strip_accents=None, sublinear_tf=False,\n",
       "           token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "           vocabulary=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(all_qns[0].dropna().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v1 = vectorizer.transform(df_train[\"question1\"].values.astype(str))\n",
    "v2 = vectorizer.transform(df_train[\"question2\"].values.astype(str))\n",
    "X = paired_cosine_distances(v1, v2).reshape(-1, 1)\n",
    "y = df_train[\"is_duplicate\"].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.688714\tvalid-logloss:0.688762\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.652626\tvalid-logloss:0.653075\n",
      "[20]\ttrain-logloss:0.627356\tvalid-logloss:0.628104\n",
      "[30]\ttrain-logloss:0.609121\tvalid-logloss:0.610089\n",
      "[40]\ttrain-logloss:0.595677\tvalid-logloss:0.596832\n",
      "[50]\ttrain-logloss:0.585652\tvalid-logloss:0.586937\n",
      "[60]\ttrain-logloss:0.578099\tvalid-logloss:0.579491\n",
      "[70]\ttrain-logloss:0.572388\tvalid-logloss:0.573862\n",
      "[80]\ttrain-logloss:0.56803\tvalid-logloss:0.569574\n",
      "[90]\ttrain-logloss:0.564691\tvalid-logloss:0.566303\n",
      "[100]\ttrain-logloss:0.562122\tvalid-logloss:0.563779\n",
      "[110]\ttrain-logloss:0.560128\tvalid-logloss:0.56183\n",
      "[120]\ttrain-logloss:0.55859\tvalid-logloss:0.560331\n",
      "[130]\ttrain-logloss:0.557396\tvalid-logloss:0.559167\n",
      "[140]\ttrain-logloss:0.556465\tvalid-logloss:0.558273\n",
      "[150]\ttrain-logloss:0.555747\tvalid-logloss:0.557584\n",
      "[160]\ttrain-logloss:0.555189\tvalid-logloss:0.557053\n",
      "[170]\ttrain-logloss:0.55474\tvalid-logloss:0.556628\n",
      "[180]\ttrain-logloss:0.554385\tvalid-logloss:0.556299\n",
      "[190]\ttrain-logloss:0.554112\tvalid-logloss:0.556047\n",
      "[200]\ttrain-logloss:0.553894\tvalid-logloss:0.555852\n",
      "[210]\ttrain-logloss:0.553721\tvalid-logloss:0.555702\n",
      "[220]\ttrain-logloss:0.553589\tvalid-logloss:0.555595\n",
      "[230]\ttrain-logloss:0.553475\tvalid-logloss:0.555506\n",
      "[240]\ttrain-logloss:0.553384\tvalid-logloss:0.555441\n",
      "[250]\ttrain-logloss:0.553315\tvalid-logloss:0.555392\n",
      "[260]\ttrain-logloss:0.553254\tvalid-logloss:0.555359\n",
      "[270]\ttrain-logloss:0.553204\tvalid-logloss:0.555331\n",
      "[280]\ttrain-logloss:0.553164\tvalid-logloss:0.555305\n",
      "[290]\ttrain-logloss:0.553131\tvalid-logloss:0.555292\n",
      "[300]\ttrain-logloss:0.553099\tvalid-logloss:0.55528\n",
      "[310]\ttrain-logloss:0.55307\tvalid-logloss:0.555274\n",
      "[320]\ttrain-logloss:0.553048\tvalid-logloss:0.555268\n",
      "[330]\ttrain-logloss:0.553024\tvalid-logloss:0.555265\n",
      "[340]\ttrain-logloss:0.553\tvalid-logloss:0.555264\n",
      "[350]\ttrain-logloss:0.552978\tvalid-logloss:0.555261\n",
      "[360]\ttrain-logloss:0.552959\tvalid-logloss:0.555258\n",
      "[370]\ttrain-logloss:0.552939\tvalid-logloss:0.555257\n",
      "[380]\ttrain-logloss:0.552918\tvalid-logloss:0.555255\n",
      "[390]\ttrain-logloss:0.552888\tvalid-logloss:0.555248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.55524520044421399"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer.scorer(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf_idf</th>\n",
       "      <th>exists_number_qn1</th>\n",
       "      <th>exists_number_qn2</th>\n",
       "      <th>number_similarity</th>\n",
       "      <th>word_difference</th>\n",
       "      <th>harsh_proper_noun_eq</th>\n",
       "      <th>proportional_proper_noun_eq</th>\n",
       "      <th>feature_hashing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.053528</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.391289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.911846</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.634852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.929178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.580686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tf_idf  exists_number_qn1  exists_number_qn2  number_similarity  \\\n",
       "0  0.053528                  0                  0                1.0   \n",
       "1  0.391289                  0                  0                1.0   \n",
       "2  0.911846                  0                  0                1.0   \n",
       "3  1.000000                  0                  1                0.0   \n",
       "4  0.929178                  0                  0                1.0   \n",
       "\n",
       "   word_difference  harsh_proper_noun_eq  proportional_proper_noun_eq  \\\n",
       "0                2                   1.0                     1.000000   \n",
       "1                5                   0.0                     1.000000   \n",
       "2                4                   0.0                     0.600000   \n",
       "3                6                   0.0                     0.333333   \n",
       "4                8                   0.0                     1.000000   \n",
       "\n",
       "   feature_hashing  \n",
       "0         0.055089  \n",
       "1         0.416667  \n",
       "2         0.634852  \n",
       "3         1.000000  \n",
       "4         0.580686  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df[\"tf_idf\"] = X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cosine-similarity of feature hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = HashingVectorizer(non_negative=False)\n",
    "w1 = vectorizer.transform(df_train[\"question1\"].values.astype(str))\n",
    "w2 = vectorizer.transform(df_train[\"question2\"].values.astype(str))\n",
    "X2 = paired_cosine_distances(w1, w2).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_df[\"feature_hashing\"] = X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.688152\tvalid-logloss:0.688198\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.647206\tvalid-logloss:0.647643\n",
      "[20]\ttrain-logloss:0.61826\tvalid-logloss:0.619048\n",
      "[30]\ttrain-logloss:0.597305\tvalid-logloss:0.59838\n",
      "[40]\ttrain-logloss:0.581771\tvalid-logloss:0.583076\n",
      "[50]\ttrain-logloss:0.570039\tvalid-logloss:0.571527\n",
      "[60]\ttrain-logloss:0.561117\tvalid-logloss:0.562774\n",
      "[70]\ttrain-logloss:0.554227\tvalid-logloss:0.556021\n",
      "[80]\ttrain-logloss:0.548918\tvalid-logloss:0.550827\n",
      "[90]\ttrain-logloss:0.544761\tvalid-logloss:0.546764\n",
      "[100]\ttrain-logloss:0.541555\tvalid-logloss:0.543631\n",
      "[110]\ttrain-logloss:0.538985\tvalid-logloss:0.541127\n",
      "[120]\ttrain-logloss:0.536938\tvalid-logloss:0.539134\n",
      "[130]\ttrain-logloss:0.535267\tvalid-logloss:0.537519\n",
      "[140]\ttrain-logloss:0.533898\tvalid-logloss:0.536209\n",
      "[150]\ttrain-logloss:0.532862\tvalid-logloss:0.535235\n",
      "[160]\ttrain-logloss:0.53203\tvalid-logloss:0.534445\n",
      "[170]\ttrain-logloss:0.531324\tvalid-logloss:0.533767\n",
      "[180]\ttrain-logloss:0.530755\tvalid-logloss:0.533234\n",
      "[190]\ttrain-logloss:0.530201\tvalid-logloss:0.532684\n",
      "[200]\ttrain-logloss:0.529784\tvalid-logloss:0.532286\n",
      "[210]\ttrain-logloss:0.529388\tvalid-logloss:0.531913\n",
      "[220]\ttrain-logloss:0.528974\tvalid-logloss:0.531521\n",
      "[230]\ttrain-logloss:0.528643\tvalid-logloss:0.531218\n",
      "[240]\ttrain-logloss:0.528358\tvalid-logloss:0.530959\n",
      "[250]\ttrain-logloss:0.528075\tvalid-logloss:0.530687\n",
      "[260]\ttrain-logloss:0.527825\tvalid-logloss:0.530451\n",
      "[270]\ttrain-logloss:0.527541\tvalid-logloss:0.530165\n",
      "[280]\ttrain-logloss:0.527235\tvalid-logloss:0.529877\n",
      "[290]\ttrain-logloss:0.526998\tvalid-logloss:0.529669\n",
      "[300]\ttrain-logloss:0.52676\tvalid-logloss:0.529461\n",
      "[310]\ttrain-logloss:0.526562\tvalid-logloss:0.529289\n",
      "[320]\ttrain-logloss:0.526373\tvalid-logloss:0.529127\n",
      "[330]\ttrain-logloss:0.526164\tvalid-logloss:0.528945\n",
      "[340]\ttrain-logloss:0.525975\tvalid-logloss:0.528784\n",
      "[350]\ttrain-logloss:0.525741\tvalid-logloss:0.528588\n",
      "[360]\ttrain-logloss:0.525569\tvalid-logloss:0.528455\n",
      "[370]\ttrain-logloss:0.525412\tvalid-logloss:0.528336\n",
      "[380]\ttrain-logloss:0.525079\tvalid-logloss:0.528025\n",
      "[390]\ttrain-logloss:0.524617\tvalid-logloss:0.527598\n",
      "Score is 0.527355080802\n",
      "[[186604  68423]\n",
      " [ 55317  93946]]\n"
     ]
    }
   ],
   "source": [
    "scorer.scorer(X_df.values, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Existence of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_checker_1 = lambda row: any(str.isdigit(char) for char in row[\"question1\"])\n",
    "num_checker_2 = lambda row: any(str.isdigit(char) for char in row[\"question2\"])\n",
    "exists_num_1 = df_train.apply(num_checker_1, axis=1, raw=True)\n",
    "exists_num_2 = df_train.apply(num_checker_2, axis=1, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_df[\"exists_number_qn1\"] = exists_num_1.astype(int)\n",
    "X_df[\"exists_number_qn2\"] = exists_num_2.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.688152\tvalid-logloss:0.688198\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.647206\tvalid-logloss:0.647643\n",
      "[20]\ttrain-logloss:0.618253\tvalid-logloss:0.619048\n",
      "[30]\ttrain-logloss:0.597276\tvalid-logloss:0.598373\n",
      "[40]\ttrain-logloss:0.581705\tvalid-logloss:0.583049\n",
      "[50]\ttrain-logloss:0.56992\tvalid-logloss:0.571469\n",
      "[60]\ttrain-logloss:0.560991\tvalid-logloss:0.56271\n",
      "[70]\ttrain-logloss:0.554084\tvalid-logloss:0.555947\n",
      "[80]\ttrain-logloss:0.548749\tvalid-logloss:0.550731\n",
      "[90]\ttrain-logloss:0.544612\tvalid-logloss:0.54669\n",
      "[100]\ttrain-logloss:0.541406\tvalid-logloss:0.543562\n",
      "[110]\ttrain-logloss:0.538833\tvalid-logloss:0.541063\n",
      "[120]\ttrain-logloss:0.536778\tvalid-logloss:0.539072\n",
      "[130]\ttrain-logloss:0.535113\tvalid-logloss:0.53748\n",
      "[140]\ttrain-logloss:0.53371\tvalid-logloss:0.536112\n",
      "[150]\ttrain-logloss:0.532656\tvalid-logloss:0.535126\n",
      "[160]\ttrain-logloss:0.531821\tvalid-logloss:0.534326\n",
      "[170]\ttrain-logloss:0.531137\tvalid-logloss:0.533683\n",
      "[180]\ttrain-logloss:0.530572\tvalid-logloss:0.533163\n",
      "[190]\ttrain-logloss:0.529992\tvalid-logloss:0.532595\n",
      "[200]\ttrain-logloss:0.52953\tvalid-logloss:0.532152\n",
      "[210]\ttrain-logloss:0.529134\tvalid-logloss:0.531781\n",
      "[220]\ttrain-logloss:0.52875\tvalid-logloss:0.53142\n",
      "[230]\ttrain-logloss:0.528411\tvalid-logloss:0.531113\n",
      "[240]\ttrain-logloss:0.528101\tvalid-logloss:0.530814\n",
      "[250]\ttrain-logloss:0.527773\tvalid-logloss:0.530484\n",
      "[260]\ttrain-logloss:0.527478\tvalid-logloss:0.530197\n",
      "[270]\ttrain-logloss:0.527097\tvalid-logloss:0.529826\n",
      "[280]\ttrain-logloss:0.526743\tvalid-logloss:0.529489\n",
      "[290]\ttrain-logloss:0.526423\tvalid-logloss:0.529181\n",
      "[300]\ttrain-logloss:0.526144\tvalid-logloss:0.528907\n",
      "[310]\ttrain-logloss:0.525875\tvalid-logloss:0.528656\n",
      "[320]\ttrain-logloss:0.525612\tvalid-logloss:0.52841\n",
      "[330]\ttrain-logloss:0.525335\tvalid-logloss:0.528164\n",
      "[340]\ttrain-logloss:0.525026\tvalid-logloss:0.527879\n",
      "[350]\ttrain-logloss:0.524675\tvalid-logloss:0.527541\n",
      "[360]\ttrain-logloss:0.52435\tvalid-logloss:0.527229\n",
      "[370]\ttrain-logloss:0.52408\tvalid-logloss:0.526979\n",
      "[380]\ttrain-logloss:0.523775\tvalid-logloss:0.526697\n",
      "[390]\ttrain-logloss:0.523543\tvalid-logloss:0.526498\n",
      "Score is 0.526331842908\n",
      "[[186602  68425]\n",
      " [ 54951  94312]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer.scorer(X_df.values, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score after adding the presence of numbers is 0.525"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def number_similarity(row):\n",
    "    str1 = row[\"question1\"]\n",
    "    str2 = row[\"question2\"]\n",
    "    str1 = \"\".join(c for c in str1 if (c.isspace() or c.isdecimal()))\n",
    "    str2 = \"\".join(c for c in str2 if (c.isspace() or c.isdecimal()))\n",
    "    numbers1 = str1.split()\n",
    "    numbers2 = str2.split()\n",
    "    numbers1.sort()\n",
    "    numbers2.sort()\n",
    "    \n",
    "    if len(numbers1) == 0 and len(numbers2) == 0:\n",
    "        return 1.\n",
    "    \n",
    "    elif len(numbers1) == 0 or len(numbers2) == 0:\n",
    "        return 0.\n",
    "    \n",
    "    if len(numbers1) > len(numbers2):\n",
    "        numbers1, numbers2 = numbers2, numbers1\n",
    "        \n",
    "    def digit_similarity(num1, num2):\n",
    "        num1 = str(num1)\n",
    "        num2 = str(num2)\n",
    "        if len(num1) > len(num2):\n",
    "            num1, num2 = num2, num1\n",
    "        \n",
    "        l = len(num2)\n",
    "        score = 0\n",
    "        for i, d in enumerate(num1):\n",
    "            if num2[i] == d:\n",
    "                score += 1\n",
    "            else:\n",
    "                break\n",
    "        return score/l\n",
    "    \n",
    "    result_list = []\n",
    "    for i, num in enumerate(numbers1):\n",
    "        result_list.append(max(map(lambda x: digit_similarity(x, num), numbers2)))\n",
    "    return sum(map(float, result_list))/len(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ns = df_train.apply(number_similarity, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         1.0\n",
      "1         1.0\n",
      "2         1.0\n",
      "3         0.0\n",
      "4         1.0\n",
      "5         1.0\n",
      "6         1.0\n",
      "7         1.0\n",
      "8         1.0\n",
      "9         1.0\n",
      "10        1.0\n",
      "11        1.0\n",
      "12        1.0\n",
      "13        1.0\n",
      "14        1.0\n",
      "15        0.0\n",
      "16        1.0\n",
      "17        1.0\n",
      "18        1.0\n",
      "19        1.0\n",
      "20        1.0\n",
      "21        1.0\n",
      "22        1.0\n",
      "23        0.0\n",
      "24        1.0\n",
      "25        1.0\n",
      "26        1.0\n",
      "27        1.0\n",
      "28        1.0\n",
      "29        1.0\n",
      "         ... \n",
      "404260    0.2\n",
      "404261    1.0\n",
      "404262    1.0\n",
      "404263    0.0\n",
      "404264    1.0\n",
      "404265    1.0\n",
      "404266    0.0\n",
      "404267    1.0\n",
      "404268    1.0\n",
      "404269    1.0\n",
      "404270    1.0\n",
      "404271    0.0\n",
      "404272    1.0\n",
      "404273    1.0\n",
      "404274    1.0\n",
      "404275    1.0\n",
      "404276    1.0\n",
      "404277    1.0\n",
      "404278    1.0\n",
      "404279    0.0\n",
      "404280    1.0\n",
      "404281    1.0\n",
      "404282    1.0\n",
      "404283    1.0\n",
      "404284    1.0\n",
      "404285    1.0\n",
      "404286    1.0\n",
      "404287    1.0\n",
      "404288    1.0\n",
      "404289    1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_df[\"number_similarity\"] = ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.688122\tvalid-logloss:0.688168\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.646925\tvalid-logloss:0.647344\n",
      "[20]\ttrain-logloss:0.61779\tvalid-logloss:0.618564\n",
      "[30]\ttrain-logloss:0.596657\tvalid-logloss:0.597742\n",
      "[40]\ttrain-logloss:0.580852\tvalid-logloss:0.582123\n",
      "[50]\ttrain-logloss:0.568755\tvalid-logloss:0.570177\n",
      "[60]\ttrain-logloss:0.559455\tvalid-logloss:0.561021\n",
      "[70]\ttrain-logloss:0.552199\tvalid-logloss:0.553874\n",
      "[80]\ttrain-logloss:0.546565\tvalid-logloss:0.548336\n",
      "[90]\ttrain-logloss:0.542183\tvalid-logloss:0.544026\n",
      "[100]\ttrain-logloss:0.538621\tvalid-logloss:0.540526\n",
      "[110]\ttrain-logloss:0.535743\tvalid-logloss:0.537694\n",
      "[120]\ttrain-logloss:0.533426\tvalid-logloss:0.535409\n",
      "[130]\ttrain-logloss:0.531541\tvalid-logloss:0.533555\n",
      "[140]\ttrain-logloss:0.52998\tvalid-logloss:0.532022\n",
      "[150]\ttrain-logloss:0.528757\tvalid-logloss:0.530831\n",
      "[160]\ttrain-logloss:0.527721\tvalid-logloss:0.529825\n",
      "[170]\ttrain-logloss:0.526807\tvalid-logloss:0.528933\n",
      "[180]\ttrain-logloss:0.52604\tvalid-logloss:0.528198\n",
      "[190]\ttrain-logloss:0.525312\tvalid-logloss:0.527502\n",
      "[200]\ttrain-logloss:0.524681\tvalid-logloss:0.526894\n",
      "[210]\ttrain-logloss:0.52412\tvalid-logloss:0.526358\n",
      "[220]\ttrain-logloss:0.523614\tvalid-logloss:0.525859\n",
      "[230]\ttrain-logloss:0.523113\tvalid-logloss:0.525362\n",
      "[240]\ttrain-logloss:0.522679\tvalid-logloss:0.524923\n",
      "[250]\ttrain-logloss:0.522316\tvalid-logloss:0.524567\n",
      "[260]\ttrain-logloss:0.52192\tvalid-logloss:0.524176\n",
      "[270]\ttrain-logloss:0.521452\tvalid-logloss:0.523693\n",
      "[280]\ttrain-logloss:0.521036\tvalid-logloss:0.52327\n",
      "[290]\ttrain-logloss:0.520677\tvalid-logloss:0.522914\n",
      "[300]\ttrain-logloss:0.52038\tvalid-logloss:0.522618\n",
      "[310]\ttrain-logloss:0.520158\tvalid-logloss:0.522403\n",
      "[320]\ttrain-logloss:0.519917\tvalid-logloss:0.52217\n",
      "[330]\ttrain-logloss:0.519563\tvalid-logloss:0.521848\n",
      "[340]\ttrain-logloss:0.519211\tvalid-logloss:0.521547\n",
      "[350]\ttrain-logloss:0.518893\tvalid-logloss:0.521257\n",
      "[360]\ttrain-logloss:0.518591\tvalid-logloss:0.520988\n",
      "[370]\ttrain-logloss:0.518335\tvalid-logloss:0.520768\n",
      "[380]\ttrain-logloss:0.518042\tvalid-logloss:0.520517\n",
      "[390]\ttrain-logloss:0.517788\tvalid-logloss:0.520282\n",
      "Score is 0.520045167554\n",
      "[[191100  63927]\n",
      " [ 56505  92758]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer.scorer(X_df.values, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is improved very slightly to 0.520."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = StringTokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_words = df_train.apply(lambda row: abs(len(nltk.word_tokenize(row[\"question1\"])) - len(nltk.word_tokenize(row[\"question2\"]))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_df[\"word_difference\"] = num_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.688091\tvalid-logloss:0.688131\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.646582\tvalid-logloss:0.646912\n",
      "[20]\ttrain-logloss:0.617087\tvalid-logloss:0.617714\n",
      "[30]\ttrain-logloss:0.595648\tvalid-logloss:0.596553\n",
      "[40]\ttrain-logloss:0.579481\tvalid-logloss:0.580555\n",
      "[50]\ttrain-logloss:0.567027\tvalid-logloss:0.568234\n",
      "[60]\ttrain-logloss:0.557361\tvalid-logloss:0.558708\n",
      "[70]\ttrain-logloss:0.549755\tvalid-logloss:0.551178\n",
      "[80]\ttrain-logloss:0.543739\tvalid-logloss:0.545224\n",
      "[90]\ttrain-logloss:0.538838\tvalid-logloss:0.540349\n",
      "[100]\ttrain-logloss:0.534939\tvalid-logloss:0.536488\n",
      "[110]\ttrain-logloss:0.531733\tvalid-logloss:0.53331\n",
      "[120]\ttrain-logloss:0.529004\tvalid-logloss:0.530599\n",
      "[130]\ttrain-logloss:0.526759\tvalid-logloss:0.528371\n",
      "[140]\ttrain-logloss:0.524979\tvalid-logloss:0.52661\n",
      "[150]\ttrain-logloss:0.523472\tvalid-logloss:0.525101\n",
      "[160]\ttrain-logloss:0.522279\tvalid-logloss:0.523937\n",
      "[170]\ttrain-logloss:0.521299\tvalid-logloss:0.522978\n",
      "[180]\ttrain-logloss:0.520476\tvalid-logloss:0.522175\n",
      "[190]\ttrain-logloss:0.519773\tvalid-logloss:0.521498\n",
      "[200]\ttrain-logloss:0.51915\tvalid-logloss:0.520877\n",
      "[210]\ttrain-logloss:0.518538\tvalid-logloss:0.520269\n",
      "[220]\ttrain-logloss:0.518018\tvalid-logloss:0.519765\n",
      "[230]\ttrain-logloss:0.517483\tvalid-logloss:0.519229\n",
      "[240]\ttrain-logloss:0.517028\tvalid-logloss:0.518793\n",
      "[250]\ttrain-logloss:0.516568\tvalid-logloss:0.518348\n",
      "[260]\ttrain-logloss:0.516164\tvalid-logloss:0.51795\n",
      "[270]\ttrain-logloss:0.515718\tvalid-logloss:0.517541\n",
      "[280]\ttrain-logloss:0.515302\tvalid-logloss:0.517153\n",
      "[290]\ttrain-logloss:0.5149\tvalid-logloss:0.516758\n",
      "[300]\ttrain-logloss:0.514529\tvalid-logloss:0.516425\n",
      "[310]\ttrain-logloss:0.5141\tvalid-logloss:0.515992\n",
      "[320]\ttrain-logloss:0.513679\tvalid-logloss:0.515593\n",
      "[330]\ttrain-logloss:0.513272\tvalid-logloss:0.515209\n",
      "[340]\ttrain-logloss:0.512942\tvalid-logloss:0.514889\n",
      "[350]\ttrain-logloss:0.512576\tvalid-logloss:0.514535\n",
      "[360]\ttrain-logloss:0.512179\tvalid-logloss:0.514157\n",
      "[370]\ttrain-logloss:0.511882\tvalid-logloss:0.513874\n",
      "[380]\ttrain-logloss:0.511512\tvalid-logloss:0.513508\n",
      "[390]\ttrain-logloss:0.511188\tvalid-logloss:0.513201\n",
      "Score is 0.513000017237\n",
      "[[189694  65333]\n",
      " [ 54618  94645]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = scorer.scorer(X_df.values, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score improved to 0.513."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf_idf</th>\n",
       "      <th>featue_hashing</th>\n",
       "      <th>exists_number_qn1</th>\n",
       "      <th>exists_number_qn2</th>\n",
       "      <th>number_similarity</th>\n",
       "      <th>word_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.053528</td>\n",
       "      <td>0.055089</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.391289</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.911846</td>\n",
       "      <td>0.634852</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.929178</td>\n",
       "      <td>0.580686</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tf_idf  featue_hashing  exists_number_qn1  exists_number_qn2  \\\n",
       "0  0.053528        0.055089                  0                  0   \n",
       "1  0.391289        0.416667                  0                  0   \n",
       "2  0.911846        0.634852                  0                  0   \n",
       "3  1.000000        1.000000                  0                  1   \n",
       "4  0.929178        0.580686                  0                  0   \n",
       "\n",
       "   number_similarity  word_difference  \n",
       "0                1.0                2  \n",
       "1                1.0                5  \n",
       "2                1.0                4  \n",
       "3                0.0                6  \n",
       "4                1.0                8  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proper nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('There', 'EX'), ('are', 'VBP'), ('two', 'CD'), ('optional', 'JJ'), ('keyword-only', 'JJ'), ('arguments.', 'IN'), ('The', 'DT'), ('key', 'JJ'), ('argument', 'NN'), ('specifies', 'VBZ'), ('a', 'DT'), ('one-argument', 'JJ'), ('ordering', 'NN'), ('function', 'NN'), ('like', 'IN'), ('that', 'DT'), ('used', 'VBD'), ('for', 'IN'), ('list.sort().', 'IN'), ('The', 'DT'), ('default', 'NN'), ('argument', 'NN'), ('specifies', 'VBZ'), ('an', 'DT'), ('object', 'NN'), ('to', 'TO'), ('return', 'VB'), ('if', 'IN'), ('the', 'DT'), ('provided', 'VBN'), ('iterable', 'NN'), ('is', 'VBZ'), ('empty.', 'JJ'), ('If', 'IN'), ('the', 'DT'), ('iterable', 'NN'), ('is', 'VBZ'), ('empty', 'JJ'), ('and', 'CC'), ('default', 'NN'), ('is', 'VBZ'), ('not', 'RB'), ('provided,', 'VB'), ('a', 'DT'), ('ValueError', 'NNP'), ('is', 'VBZ'), ('raised.', 'JJ')]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"There are two optional keyword-only arguments. The key argument specifies a one-argument ordering function like that used for list.sort(). The default argument specifies an object to return if the provided iterable is empty. If the iterable is empty and default is not provided, a ValueError is raised.\"\n",
    "tagged_sent = pos_tag(sentence.split())\n",
    "print(tagged_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ValueError', 'NNP')\n"
     ]
    }
   ],
   "source": [
    "for tup in tagged_sent:\n",
    "    if tup[1] == \"NNP\":\n",
    "        print(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def harsh_proper_noun_equality(row):\n",
    "    global n\n",
    "    proper_nouns_set1 = set(word for word, wordtype in pos_tag(row[\"question1\"]) if wordtype == \"NNP\")\n",
    "    proper_nouns_set2 = set(word for word, wordtype in pos_tag(row[\"question2\"]) if wordtype == \"NNP\")\n",
    "    n += 1\n",
    "    if n % 1000 == 0:\n",
    "        print(n // 1000)\n",
    "        \n",
    "    if len(proper_nouns_set1) == 0 and len(proper_nouns_set2) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    if set(proper_nouns_set1) == set(proper_nouns_set2):\n",
    "        return 1\n",
    "    \n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def proportional_proper_noun_equality(row):\n",
    "    global n\n",
    "    n += 1\n",
    "    if n % 1000 == 0:\n",
    "        print(n // 1000)\n",
    "        \n",
    "    if not (type(row[\"question1\"]) == str and type(row[\"question2\"])) == str:\n",
    "        return 0\n",
    "        \n",
    "    proper_nouns_set1 = set(word for word, wordtype in pos_tag(row[\"question1\"]) if wordtype == \"NNP\")\n",
    "    proper_nouns_set2 = set(word for word, wordtype in pos_tag(row[\"question2\"]) if wordtype == \"NNP\")\n",
    "    if len(proper_nouns_set1) == 0 and len(proper_nouns_set2) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    elif len(proper_nouns_set1) == 0 or len(proper_nouns_set2) == 0:\n",
    "        return 0\n",
    "    \n",
    "    intersect = proper_nouns_set1 & proper_nouns_set2\n",
    "    numerator = len(intersect)\n",
    "    denominator = min(map(len, [proper_nouns_set1, proper_nouns_set2]))\n",
    "    \n",
    "    return numerator/denominator\n",
    "    \n",
    "n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n"
     ]
    }
   ],
   "source": [
    "hpne = df_train.apply(harsh_proper_noun_equality, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_df[\"harsh_proper_noun_eq\"] = hpne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_df.to_csv(\"X_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.688034\tvalid-logloss:0.688062\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.646112\tvalid-logloss:0.646383\n",
      "[20]\ttrain-logloss:0.616026\tvalid-logloss:0.616589\n",
      "[30]\ttrain-logloss:0.593923\tvalid-logloss:0.59474\n",
      "[40]\ttrain-logloss:0.577308\tvalid-logloss:0.578325\n",
      "[50]\ttrain-logloss:0.564601\tvalid-logloss:0.565761\n",
      "[60]\ttrain-logloss:0.554738\tvalid-logloss:0.556032\n",
      "[70]\ttrain-logloss:0.546863\tvalid-logloss:0.548275\n",
      "[80]\ttrain-logloss:0.540589\tvalid-logloss:0.542079\n",
      "[90]\ttrain-logloss:0.535447\tvalid-logloss:0.536991\n",
      "[100]\ttrain-logloss:0.531276\tvalid-logloss:0.532876\n",
      "[110]\ttrain-logloss:0.52781\tvalid-logloss:0.529472\n",
      "[120]\ttrain-logloss:0.524973\tvalid-logloss:0.526685\n",
      "[130]\ttrain-logloss:0.522612\tvalid-logloss:0.524354\n",
      "[140]\ttrain-logloss:0.520688\tvalid-logloss:0.522437\n",
      "[150]\ttrain-logloss:0.519044\tvalid-logloss:0.520812\n",
      "[160]\ttrain-logloss:0.517663\tvalid-logloss:0.519433\n",
      "[170]\ttrain-logloss:0.516503\tvalid-logloss:0.518288\n",
      "[180]\ttrain-logloss:0.515522\tvalid-logloss:0.517316\n",
      "[190]\ttrain-logloss:0.514643\tvalid-logloss:0.51646\n",
      "[200]\ttrain-logloss:0.513892\tvalid-logloss:0.515715\n",
      "[210]\ttrain-logloss:0.513147\tvalid-logloss:0.514976\n",
      "[220]\ttrain-logloss:0.512511\tvalid-logloss:0.514361\n",
      "[230]\ttrain-logloss:0.5119\tvalid-logloss:0.513756\n",
      "[240]\ttrain-logloss:0.511432\tvalid-logloss:0.513305\n",
      "[250]\ttrain-logloss:0.510905\tvalid-logloss:0.512784\n",
      "[260]\ttrain-logloss:0.510389\tvalid-logloss:0.512266\n",
      "[270]\ttrain-logloss:0.509951\tvalid-logloss:0.511836\n",
      "[280]\ttrain-logloss:0.509493\tvalid-logloss:0.511402\n",
      "[290]\ttrain-logloss:0.509072\tvalid-logloss:0.510998\n",
      "[300]\ttrain-logloss:0.508714\tvalid-logloss:0.510662\n",
      "[310]\ttrain-logloss:0.5082\tvalid-logloss:0.510156\n",
      "[320]\ttrain-logloss:0.50776\tvalid-logloss:0.509734\n",
      "[330]\ttrain-logloss:0.507332\tvalid-logloss:0.509327\n",
      "[340]\ttrain-logloss:0.507015\tvalid-logloss:0.50903\n",
      "[350]\ttrain-logloss:0.506721\tvalid-logloss:0.508761\n",
      "[360]\ttrain-logloss:0.506362\tvalid-logloss:0.508431\n",
      "[370]\ttrain-logloss:0.506007\tvalid-logloss:0.508094\n",
      "[380]\ttrain-logloss:0.505725\tvalid-logloss:0.507811\n",
      "[390]\ttrain-logloss:0.505437\tvalid-logloss:0.507546\n",
      "Score is 0.507283110992\n",
      "[[198100  56927]\n",
      " [ 59747  89516]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer.scorer(X_df.values, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score improved to 0.5072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(verbose=100, C=0.1)\n",
    "svc.fit(X_df.values, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_df[\"harsh_proper_noun_eq\"].fillna(X_df[\"harsh_proper_noun_eq\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66226718444680799"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.score(X_df.values, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_df = pd.read_csv(\"X_df.csv\")\n",
    "df_train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n"
     ]
    }
   ],
   "source": [
    "ppne = df_train.apply(proportional_proper_noun_equality, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_df[\"proportional_proper_noun_eq\"].fillna(X_df[\"proportional_proper_noun_eq\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How can I develop android app?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[105780, \"question1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_df[\"proportional_proper_noun_eq\"] = ppne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.688034\tvalid-logloss:0.688062\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.645861\tvalid-logloss:0.646142\n",
      "[20]\ttrain-logloss:0.615713\tvalid-logloss:0.616252\n",
      "[30]\ttrain-logloss:0.593532\tvalid-logloss:0.594312\n",
      "[40]\ttrain-logloss:0.576912\tvalid-logloss:0.577879\n",
      "[50]\ttrain-logloss:0.564043\tvalid-logloss:0.565153\n",
      "[60]\ttrain-logloss:0.554048\tvalid-logloss:0.555292\n",
      "[70]\ttrain-logloss:0.546098\tvalid-logloss:0.547457\n",
      "[80]\ttrain-logloss:0.539833\tvalid-logloss:0.541256\n",
      "[90]\ttrain-logloss:0.53461\tvalid-logloss:0.536089\n",
      "[100]\ttrain-logloss:0.53035\tvalid-logloss:0.531894\n",
      "[110]\ttrain-logloss:0.526866\tvalid-logloss:0.528448\n",
      "[120]\ttrain-logloss:0.524016\tvalid-logloss:0.525643\n",
      "[130]\ttrain-logloss:0.521592\tvalid-logloss:0.52323\n",
      "[140]\ttrain-logloss:0.519616\tvalid-logloss:0.521301\n",
      "[150]\ttrain-logloss:0.517917\tvalid-logloss:0.519621\n",
      "[160]\ttrain-logloss:0.516575\tvalid-logloss:0.518315\n",
      "[170]\ttrain-logloss:0.515385\tvalid-logloss:0.517152\n",
      "[180]\ttrain-logloss:0.514341\tvalid-logloss:0.516153\n",
      "[190]\ttrain-logloss:0.513348\tvalid-logloss:0.515189\n",
      "[200]\ttrain-logloss:0.512509\tvalid-logloss:0.51439\n",
      "[210]\ttrain-logloss:0.511775\tvalid-logloss:0.513661\n",
      "[220]\ttrain-logloss:0.511107\tvalid-logloss:0.513033\n",
      "[230]\ttrain-logloss:0.510456\tvalid-logloss:0.512428\n",
      "[240]\ttrain-logloss:0.509812\tvalid-logloss:0.511806\n",
      "[250]\ttrain-logloss:0.509254\tvalid-logloss:0.511267\n",
      "[260]\ttrain-logloss:0.508744\tvalid-logloss:0.510773\n",
      "[270]\ttrain-logloss:0.508143\tvalid-logloss:0.510193\n",
      "[280]\ttrain-logloss:0.5076\tvalid-logloss:0.509675\n",
      "[290]\ttrain-logloss:0.507097\tvalid-logloss:0.509176\n",
      "[300]\ttrain-logloss:0.506542\tvalid-logloss:0.508665\n",
      "[310]\ttrain-logloss:0.506044\tvalid-logloss:0.508217\n",
      "[320]\ttrain-logloss:0.505634\tvalid-logloss:0.507824\n",
      "[330]\ttrain-logloss:0.505296\tvalid-logloss:0.507506\n",
      "[340]\ttrain-logloss:0.504879\tvalid-logloss:0.507114\n",
      "[350]\ttrain-logloss:0.504452\tvalid-logloss:0.506725\n",
      "[360]\ttrain-logloss:0.504077\tvalid-logloss:0.506381\n",
      "[370]\ttrain-logloss:0.503683\tvalid-logloss:0.506012\n",
      "[380]\ttrain-logloss:0.50325\tvalid-logloss:0.505597\n",
      "[390]\ttrain-logloss:0.502867\tvalid-logloss:0.505239\n",
      "Score is 0.504979490064\n",
      "[[194791  60236]\n",
      " [ 55654  93609]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer.scorer(X_df.values, df_train[\"is_duplicate\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(hidden_layer_sizes=(100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_df.values, df_train[\"is_duplicate\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf_idf</th>\n",
       "      <th>featue_hashing</th>\n",
       "      <th>exists_number_qn1</th>\n",
       "      <th>exists_number_qn2</th>\n",
       "      <th>number_similarity</th>\n",
       "      <th>word_difference</th>\n",
       "      <th>harsh_proper_noun_eq</th>\n",
       "      <th>proportional_proper_noun_eq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>404290.000000</td>\n",
       "      <td>404290.000000</td>\n",
       "      <td>404290.000000</td>\n",
       "      <td>404290.000000</td>\n",
       "      <td>404290.000000</td>\n",
       "      <td>404290.000000</td>\n",
       "      <td>404290.000000</td>\n",
       "      <td>404290.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.667479</td>\n",
       "      <td>0.495216</td>\n",
       "      <td>0.116451</td>\n",
       "      <td>0.120092</td>\n",
       "      <td>0.896305</td>\n",
       "      <td>4.098682</td>\n",
       "      <td>0.318765</td>\n",
       "      <td>0.855398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.282922</td>\n",
       "      <td>0.256946</td>\n",
       "      <td>0.320765</td>\n",
       "      <td>0.325070</td>\n",
       "      <td>0.298716</td>\n",
       "      <td>5.519718</td>\n",
       "      <td>0.465958</td>\n",
       "      <td>0.222409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.480763</td>\n",
       "      <td>0.292893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.744054</td>\n",
       "      <td>0.496047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.898292</td>\n",
       "      <td>0.683772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>257.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tf_idf  featue_hashing  exists_number_qn1  exists_number_qn2  \\\n",
       "count  404290.000000   404290.000000      404290.000000      404290.000000   \n",
       "mean        0.667479        0.495216           0.116451           0.120092   \n",
       "std         0.282922        0.256946           0.320765           0.325070   \n",
       "min         0.000000        0.000000           0.000000           0.000000   \n",
       "25%         0.480763        0.292893           0.000000           0.000000   \n",
       "50%         0.744054        0.496047           0.000000           0.000000   \n",
       "75%         0.898292        0.683772           0.000000           0.000000   \n",
       "max         1.000000        1.000000           1.000000           1.000000   \n",
       "\n",
       "       number_similarity  word_difference  harsh_proper_noun_eq  \\\n",
       "count      404290.000000    404290.000000         404290.000000   \n",
       "mean            0.896305         4.098682              0.318765   \n",
       "std             0.298716         5.519718              0.465958   \n",
       "min             0.000000         0.000000              0.000000   \n",
       "25%             1.000000         1.000000              0.000000   \n",
       "50%             1.000000         2.000000              0.000000   \n",
       "75%             1.000000         5.000000              1.000000   \n",
       "max             1.000000       257.000000              1.000000   \n",
       "\n",
       "       proportional_proper_noun_eq  \n",
       "count                404290.000000  \n",
       "mean                      0.855398  \n",
       "std                       0.222409  \n",
       "min                       0.000000  \n",
       "25%                       0.666667  \n",
       "50%                       1.000000  \n",
       "75%                       1.000000  \n",
       "max                       1.000000  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_res = clf.predict_proba(X_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.493570603419\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "print(log_loss(y, y_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Question type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-ba3db5f4537d>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-ba3db5f4537d>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    result =\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def determine_qn_type(row):\n",
    "    qn1 = nltk.word_tokenize(row[\"question1\"])\n",
    "    qn2 = nltk.word_tokenize(row[\"question2\"])\n",
    "    result = 1\n",
    "    for qn_identifier in [\"who\", \"where\", \"when\", \"how\", \"why\"]:\n",
    "        if not bool(qn_identifier in qn1) == bool(qn_identifier in qn2):\n",
    "            result = 0\n",
    "            return result\n",
    "        \n",
    "    for qn in [qn1, qn2]:\n",
    "        if \"what\" in qn:\n",
    "            result = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How', 'is', 'your', 'day', '?']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(\"How is your day?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('How', 'WRB'), ('is', 'VBZ'), ('your', 'PRP$'), ('day', 'NN'), ('?', '.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(nltk.word_tokenize(\"How is your day?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
